{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#autor Rafael RR\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import tree\n",
    "import pickle\n",
    "import re\n",
    "import sklearn\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "import pickle\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "archivo_train=\"base.csv\"\n",
    "nombre_ia=\"rafa_bot.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "#se crean las funciones de preproceso\n",
    "def procesa_texto():\n",
    "    cols=[\"tema\",\"real\"]\n",
    "    cols_train=\"texto\"\n",
    "    col_layer=\"real\"\n",
    "    df=pd.read_csv(archivo_train,encoding ='latin1')    \n",
    "    X_df = df\n",
    "    X_df =sklearn.utils.shuffle(X_df)\n",
    "    \n",
    "    text = X_df[[cols_train]]\n",
    "    Y = X_df[col_layer]\n",
    "    \n",
    "    l_texto=[]\n",
    "    \n",
    "    for i in range(0, len(text)):\n",
    "        # Remueve caracteres especiales\n",
    "        texto_aux = re.sub(r'\\W', ' ', str(text[\"texto\"][i]))\n",
    "        \n",
    "        # Sustituimos varios en espacios blanco por uno solo\n",
    "        texto_aux = re.sub(r'\\s+', ' ', texto_aux, flags=re.I)\n",
    "        #print(text[\"texto\"][i])\n",
    "        \n",
    "        # Convierte a minusculas\n",
    "        texto_aux = texto_aux.lower()\n",
    "        \n",
    "        l_texto.append(texto_aux)\n",
    "    \n",
    "    # bolsa de palabras\n",
    "    # remover stopwords\n",
    "    vectorizer = CountVectorizer(stop_words=stopwords.words('spanish'))\n",
    "    \n",
    "    X = vectorizer.fit_transform(l_texto).toarray()\n",
    " \n",
    "    tfidfconverter = TfidfTransformer()\n",
    "    \n",
    "    X = tfidfconverter.fit_transform(X).toarray()\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=10)\n",
    "    modelo_tema=crea_modelo(data=X_train, etiqueta=y_train)\n",
    "    \n",
    "    \n",
    "    estadistica_modelo(modelo_tema, X_test, y_test, nombre_ia)\n",
    "    \n",
    "    return [vectorizer, tfidfconverter]\n",
    "\n",
    "def crea_modelo(data, etiqueta):\n",
    "    #se encuentran varios modelos para que se realizen las pruebas del mejor modelo \n",
    "    #solo es necesario descomentar el modelo que se desea\n",
    "    #modelo =SGDClassifier(loss='hinge', penalty='l2', \n",
    "     #                     alpha=1e-3, random_state=1, max_iter=2, tol=None)\n",
    "    #modelo =MLPClassifier(solver='sgd', \n",
    "                  #alpha=1e-5,\n",
    "                  #hidden_layer_sizes=(10, 20), random_state=1)\n",
    "    modelo = BernoulliNB()\n",
    "    #modelo = MLPClassifier(hidden_layer_sizes=(200,100,500), \n",
    "     #                      activation='relu', solver='adam', max_iter=5000)\n",
    "    \n",
    "    #modelo = RandomForestClassifier(n_estimators=1000, random_state=0)\n",
    "    modelo.fit(data, etiqueta)\n",
    "    return modelo\n",
    "\n",
    "def estadistica_modelo(modelo, X_test, y_test, nombre_ia):\n",
    "    y_pred = modelo.predict(X_test)\n",
    "    \n",
    "    #Evaluating the Model\n",
    "    print (\"---------------------------------------\\n\")\n",
    "    print (\"matriz de confunsion\")\n",
    "    print(confusion_matrix(y_test,y_pred))\n",
    "    \n",
    "    print (\"---------------------------------------\\n\")\n",
    "    print(classification_report(y_test,y_pred))\n",
    "    \n",
    "    print (\"---------------------------------------\\n\")\n",
    "    exito=int(accuracy_score(y_test, y_pred)*100)\n",
    "    print(\"el exito del modelo es: \"+str(exito)+ \"%\")\n",
    "    \n",
    "    print (\"---------------------------------------\\n\")\n",
    "    #guardamos el modelo \n",
    "    with open(nombre_ia, 'wb') as picklefile:\n",
    "        pickle.dump(modelo,picklefile)\n",
    "        \n",
    "def usa_modelo(vectorizer, tfidfconverter, texto):\n",
    "    #docs_new = ['hola soy nuevo', 'jonh titor']\n",
    "    docs_new = [texto]\n",
    "    X_new_counts = vectorizer.transform(docs_new)\n",
    "    X_new_tfidf = tfidfconverter.transform(X_new_counts).toarray()\n",
    "    \n",
    "    with open(nombre_ia, 'rb') as training_model:\n",
    "        modelo = pickle.load(training_model)\n",
    "    \n",
    "    predicted = modelo.predict(X_new_tfidf)\n",
    "    return predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# se entrena el modelo , espera unos minutos ..\n",
    "\n",
    "l_contexto=procesa_texto()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "introduce un texto que pueda ser una noticia falsa:\n",
      "sad asdas dasd\n",
      "\n",
      " El bot determino que la noticia es falsa \n"
     ]
    }
   ],
   "source": [
    "print(\"introduce un texto que pueda ser una noticia falsa:\")\n",
    "texto=  input()\n",
    "vectorizer=l_contexto[0]\n",
    "tfidfconverter=l_contexto[1]\n",
    "res=usa_modelo(vectorizer, tfidfconverter, texto)\n",
    "\n",
    "if 0 == res[0]:\n",
    "    print (\"\\n El bot determino que la noticia es falsa \")\n",
    "else:\n",
    "    print (\"\\n El bot determino que la noticia es verdadera \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
